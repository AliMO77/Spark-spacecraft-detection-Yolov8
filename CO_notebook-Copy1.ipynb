{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "curr_dir ='/home/users/maali/Computer_vision_SOC'\n",
    "sys.path.append(curr_dir)\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from ImageProcessor import ImageProcessor\n",
    "from Dataset import CustomImageDataGenerator\n",
    "def get_run_logdir(root_logdir):\n",
    "    import time \n",
    "    run_id = time.strftime(\"run_%y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir,run_id)\n",
    "\n",
    "run_logdir = get_run_logdir(os.path.join(curr_dir,\"my_logs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_image_folder = '/home/users/maali/Computer_vision_SOC/spark-2022-stream-1/train/'\n",
    "val_image_folder = '/home/users/maali/Computer_vision_SOC/spark-2022-stream-1/val/'\n",
    "test_image_folder = '/home/users/maali/Computer_vision_SOC/spark-2022-stream-1/test/'\n",
    "\n",
    "\n",
    "train_data_csv = '/home/users/maali/Computer_vision_SOC/spark-2022-stream-1/labels/train.csv'\n",
    "val_data_csv = '/home/users/maali/Computer_vision_SOC/spark-2022-stream-1/labels/val.csv'\n",
    "\n",
    "\n",
    "image_processor = ImageProcessor(train_image_folder,val_image_folder,train_data_csv,val_data_csv)\n",
    "\n",
    "train_data_pd,val_data_pd = image_processor.train_df,image_processor.val_df\n",
    "\n",
    "#image_processor.display_random_image_per_class(train_data_pd)\n",
    "#image_processor.plot_feature_distribution(train_data_pd, 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 09:14:12.344634: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the batch size and image size\n",
    "batch_size = 32\n",
    "image_size = (256, 256)\n",
    "sample_size= 20000\n",
    "# Create the custom data generator\n",
    "train_generator = CustomImageDataGenerator(train_data_pd, train_image_folder, image_size=image_size,batch_size=batch_size)\n",
    "val_generator = CustomImageDataGenerator(val_data_pd, val_image_folder,image_size=image_size,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 09:15:02.804147: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-10-17 09:15:02.804185: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2023-10-17 09:15:02.804229: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2023-10-17 09:15:02.815084: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 11\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-10-17 09:15:02.863225: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-10-17 09:15:02.875664: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2600000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/2062 [..............................] - ETA: 5:17:02 - loss: 2.3976 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 09:15:12.301191: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2023-10-17 09:15:12.301222: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2/2062 [..............................] - ETA: 1:06:26 - loss: 2.3873 - accuracy: 0.2969    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 09:15:14.049885: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-10-17 09:15:14.053087: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2023-10-17 09:15:14.059024: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14\n",
      "2023-10-17 09:15:14.062699: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14/iris-112.trace.json.gz\n",
      "2023-10-17 09:15:14.065588: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14\n",
      "2023-10-17 09:15:14.066051: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14/iris-112.memory_profile.json.gz\n",
      "2023-10-17 09:15:14.068542: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14Dumped tool data for xplane.pb to /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14/iris-112.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14/iris-112.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14/iris-112.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14/iris-112.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /home/users/maali/Computer_vision_SOC/my_logs/run_23_10_17-09_14_11/train/plugins/profile/2023_10_17_09_15_14/iris-112.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2062/2062 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 10:15:26.741269: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 11\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2062/2062 [==============================] - 4734s 2s/step - loss: 0.3779 - accuracy: 0.8828 - val_loss: 14.7746 - val_accuracy: 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 10:33:57.459568: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: spacecraft_classifier/assets\n",
      "Epoch 2/100\n",
      "   1/2062 [..............................] - ETA: 29:46 - loss: 4.0599e-04 - accuracy: 1.0000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 206200 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m reduce_lr \u001b[39m=\u001b[39m ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m# Train the model using the train_model method\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m transfer_vgg16\u001b[39m.\u001b[39;49mtrain_model(train_generator, val_generator, callbacks\u001b[39m=\u001b[39;49m[tensorboard_cb, checkpoint_cb, early_stopping_cb, reduce_lr], epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m transfer_vgg16\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mspacecraft_classifier\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(\u001b[39mself\u001b[39m, train_gen, val_gen, callbacks\u001b[39m=\u001b[39m[], epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mscope():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m             train_gen\u001b[39m.\u001b[39;49mdata,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m             validation_data\u001b[39m=\u001b[39;49mval_gen\u001b[39m.\u001b[39;49mdata,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m             epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m             steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_gen),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m             validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(val_gen)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Biris-cluster/home/users/maali/Computer_vision_SOC/CO_notebook-Copy1.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m         )\n",
      "File \u001b[0;32m/opt/apps/resif/iris-rhel8/2020b/broadwell/software/TensorFlow/2.5.0-foss-2020b/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1214\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1201\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1202\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1203\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1212\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1213\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1214\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1215\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1216\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1217\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1218\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1219\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1220\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1221\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1222\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1223\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1224\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1225\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1226\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m   1227\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/opt/apps/resif/iris-rhel8/2020b/broadwell/software/TensorFlow/2.5.0-foss-2020b/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1489\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1488\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1489\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   1490\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1491\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/apps/resif/iris-rhel8/2020b/broadwell/software/TensorFlow/2.5.0-foss-2020b/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/apps/resif/iris-rhel8/2020b/broadwell/software/TensorFlow/2.5.0-foss-2020b/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:924\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    922\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    925\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    926\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    927\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/apps/resif/iris-rhel8/2020b/broadwell/software/TensorFlow/2.5.0-foss-2020b/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   3021\u001b[0m   (graph_function,\n\u001b[1;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/apps/resif/iris-rhel8/2020b/broadwell/software/TensorFlow/2.5.0-foss-2020b/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m     args,\n\u001b[1;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1965\u001b[0m     executing_eagerly)\n\u001b[1;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/apps/resif/iris-rhel8/2020b/broadwell/software/TensorFlow/2.5.0-foss-2020b/lib/python3.8/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/apps/resif/iris-rhel8/2020b/broadwell/software/TensorFlow/2.5.0-foss-2020b/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class TransferVGG16:\n",
    "    def __init__(self, input_shape=(224, 224, 3), num_classes=11):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.strategy = tf.distribute.MirroredStrategy()  # Initialize MirroredStrategy\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        with self.strategy.scope():  # Create model within the strategy scope\n",
    "            base_model = VGG16(\n",
    "                include_top=False,\n",
    "                weights='imagenet',\n",
    "                input_shape=self.input_shape\n",
    "            )\n",
    "            \n",
    "            for layer in base_model.layers:\n",
    "                layer.trainable = False\n",
    "\n",
    "            model = models.Sequential()\n",
    "            model.add(base_model)\n",
    "\n",
    "            model.add(Conv2D(64, (7, 7), 1, activation='relu', padding='same'))\n",
    "            model.add(MaxPooling2D())\n",
    "\n",
    "            model.add(Conv2D(128, (7, 7), 1, activation='relu', padding='same'))\n",
    "            model.add(MaxPooling2D())\n",
    "\n",
    "            model.add(Conv2D(512, (7, 7), 1, activation='relu', padding='same'))\n",
    "            model.add(MaxPooling2D())\n",
    "\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(4096, activation='relu'))\n",
    "            model.add(layers.Dense(4096, activation='relu'))\n",
    "            model.add(layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def compile_model(self, learning_rate=0.001):\n",
    "        with self.strategy.scope():\n",
    "            optimizer = Adam(learning_rate=learning_rate, epsilon=0.01)\n",
    "            loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "            metrics = ['accuracy']\n",
    "\n",
    "            self.model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
    "\n",
    "    def train_model(self, train_gen, val_gen, callbacks=[], epochs=10):\n",
    "        with self.strategy.scope():\n",
    "            self.model.fit(\n",
    "                train_gen.data,\n",
    "                validation_data=val_gen.data,\n",
    "                callbacks=callbacks,\n",
    "                epochs=epochs,\n",
    "                steps_per_epoch=len(train_gen),\n",
    "                validation_steps=len(val_gen)\n",
    "            )\n",
    "\n",
    "    def evaluate_model(self, test_images, test_labels):\n",
    "        evaluation_metrics = self.model.evaluate(test_images, test_labels)\n",
    "        return {\n",
    "            'loss': evaluation_metrics[0],\n",
    "            'accuracy': evaluation_metrics[1]\n",
    "        }\n",
    "\n",
    "# Create the TransferVGG16 instance\n",
    "transfer_vgg16 = TransferVGG16(input_shape=(image_size[0], image_size[1], 3), num_classes=11)\n",
    "\n",
    "# Compile the model\n",
    "transfer_vgg16.compile_model()\n",
    "\n",
    "# Define your callbacks\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"spacecraft_classifier\", save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train the model using the train_model method\n",
    "transfer_vgg16.train_model(train_generator, val_generator, callbacks=[tensorboard_cb, checkpoint_cb, early_stopping_cb, reduce_lr], epochs=100)\n",
    "\n",
    "# Save the model\n",
    "transfer_vgg16.model.save(\"spacecraft_classifier\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupenv",
   "language": "python",
   "name": "jupenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
